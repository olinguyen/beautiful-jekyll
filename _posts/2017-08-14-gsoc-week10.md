---
layout: post
title: Google Summer of Code - Week 10
# bigimg: /img/gsoc-logo.png
tags: [gsoc, data-science, machine-learning]
---

For week 10, I started to exploit the temporal information from the MIMIC database in order to make mortality predictions. If we recall the first models that were built, I extracted the vital signs from the first 24 hours a patient entering the ICU and compute features like the mean, min and max over that time period to construct a feature vector for a single patient. This method fails to account for the fluctuations of the vital signs over time and most importantly does not look at how the vital signs change moments before death. The previous model makes it difficult to incorporate in a real-time clinical monitoring system where it is possible to look at a patient at any time and make a prediction about whether the patient will die within a certain amount of time.

To build a new model that is more suited for real-time clinical monitoring, I started by extracting every vital sign data point of the first 24 hours of a patient upon entering the ICU. The raw vital signs of a patient looks as follows:

![](/img/week10/single-patient-vitals.png "Patient Vital Signs")

As observed from the plot, data points come in a irregular time intervals, which requires resampling to make it easier to compute features. The vital signs were downsampled to every hour, for the first 24 hours. Afterwards, lagged observations (t-1), which are the vital signs at the previous hour, were computed by shifting columns with a previous time stamp. A rolling window is then computes the mean, min, max and median over the entire vital signs time series of a patient in the last 6 hours. Below is a sample of data points with only heart rate used.

| timestamp           | heartrate-raw | hr_1h | hr_max_6h | hr_mean_6h | hr_median_6h | hr_min_6h |
|---------------------|---------------|-------|-----------|------------|--------------|-----------|
| 2100-06-09 13:00:00 | 90.0          | 74.0  | 90.0      | 79.857143  | 77.0         | 74.0      |
| 2100-06-09 14:00:00 | 81.0          | 90.0  | 90.0      | 79.285714  | 77.0         | 74.0      |
| 2100-06-09 15:00:00 | 79.0          | 81.0  | 90.0      | 79.000000  | 77.0         | 74.0      |
| 2100-06-09 16:00:00 | 79.0          | 79.0  | 90.0      | 79.428571  | 79.0         | 74.0      |
| 2100-06-09 17:00:00 | 68.0          | 79.0  | 90.0      | 78.142857  | 79.0         | 68.0      |
| 2100-06-09 19:00:00 | 74.0          | 68.0  | 90.0      | 77.857143  | 79.0         | 68.0      |
| 2100-06-09 20:00:00 | 71.0          | 74.0  | 90.0      | 77.428571  | 79.0         | 68.0      |
|                     |               |       |           |            |              |           |

The features for a dying patient can be visualized below:

![](/img/week10/features-patient.png "Patient Features")

Every row above contains a label outcome, indicating if the patient will die in 1 day and 7 days from that specific timestamp, which is then used as training data for a classifier. 

In addition to the vital signs and their lagged features, I included demographic information regarding the patient, as was included in the previous models that I built. The results for 1-day and 7-day mortality were recorded in the table below.

| Classifier          | Mean AUC across 10 folds (%) ||
|---------------------|---------------------------|----------------------------|
|                     | 1-day Hospital mortality  | 7-day Hospital mortality   |
| Logistic Regression | 73.48                     | 71.71                      |
| Linear SVM          | 73.22                     | 71.54                      |

## Up Next

* Not all features from the previous models were included in this new one. This is because data from laboratory measurements are made at a different time points, mostly after the first 24 hours of staying in the ICU, which is thus not available in the current problem. Nonetheless, there are cased (not always) when some features are available, which can be determined by looking at the timestamp.

* Class imbalance: there are much more negative samples (patients that survive) than positive samples. This is especially the case since I'm only using the first 24 hours of vital signs and fewer people die within that time span. I'll have to look into approaches to better balance the training data.

* Because the training data is over 350,000 points, the Random Forest classifier takes too much time to compute. I probably will have to reduce the dataset size in order to evaluate Random Forests.

* Recurrent neural networks have shown to be effective when dealing with time series data and sequences as it can capture information from previous time points. Currently, Shogun is missing an RNN module, which I intend to develop and implement so that it can be used and tested for the MIMIC database.