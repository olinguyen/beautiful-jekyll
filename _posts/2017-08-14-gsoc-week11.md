---
layout: post
title: Google Summer of Code - Final Week
# bigimg: /img/gsoc-logo.png
tags: [gsoc, data-science, machine-learning]
---

### Introduction

Electronic health records (EHR) have generated a great amount of health data. Utilizing EHR data could provide health professionals with evidence-based decision making by estimating individual probabilitys of risks and benefits.

### Objectives

For this data project, I focused on the problem of mortality prediction and survival analysis. More specifically, I was interested in developing a model that could allow caregivers to monitor and predict mortality of patients. In practice, such a system would be incorporated in a real-time clinical monitoring system where it would be possible to look at a patient at any point in time and make a prediction about whether the patient will die within a certain amount of time. Using the MIMIC database which includes vital signs, medications, diagnostic code and many more variables, along with feature engineering techniques, I investigated whether I could build a robust classifier to perform such mortality prediction task.

In addition to the prediction task, I wanted to model and understand how a dying patient differs from a patient with normal behavior moments before days, hours and right before death.

### Model

#### Improved model with temporal and lagged features
In this improved model, I exploit the temporal information, taking into account the fluctuations of the vital signs over time and most importantly does not look at how the vital signs change moments before death.

The vital signs were downsampled to every hour, for the first 24 hours. Afterwards, lagged features from the last 3 observations (t-1, t-2, t-3), which are the vital signs at the previous hours, were computed by shifting columns of the time stamp. A rolling window is then computes the mean, min, max and median over the entire vital signs time series of a patient in the last 6 hours. Below is a sample of data points with only heart rate used. The list of vital signs used as features can be seen in the table below.

| Vital sign               | Description |
|--------------------------|-------------|
| Heart Rate               | Heartbeat rate of the patient |
| Mean Blood Pressure      | Average pressure in a patient's arteries during one cardiac cycle       |
| Diastolic blood pressure | Pressure when the heart is at rest between beats            |
| Systolic blood pressure  | Pressure when the heart is beating |
| Respiratory Rate         | Number of breaths taken per minute       |
| Temperature              | Temperature of a patient in degrees Celcius            |
| SpO2                     | Amount of oxygen in the blood            |

To observe how these features differ between dying and surviving patients, a stacked histogram was plotted to view the distribution of these vital signs values across both groups. 

![](/img/finalweek/vitals-comparison.png "Vital Sign comparison")

In the end, the features included vital signs, their lagged observations and window computations, demographic information and the hospital length of stay of the patient. Three classifiers (logistic regression, linear SVM and random forest) were evaluated and compared. The feature matrix was constructed where a single row represented a patient observation at a certain point in time with the features mentionned above. Because the entire dataset consists of over 500,000, the training and testing set were sampled and evaluated several times. The subset of the data consisted of 100,000 points. The results were recorded in the following table.

| Classifier          | Test set AUC score (%)    |                            |
|---------------------|---------------------------|----------------------------|
|                     | 1-day Hospital mortality  | 7-day Hospital mortality   |
| Logistic Regression | 73.48                     | 71.71                      |
| Linear SVM          | 73.22                     | 71.54                      |
| Random Forest       | 79.35                     | 79.64                 |

Random forest produced the best results among all three classifiers for 1-day and 1-week mortality prediction. The variance across the 10 runs with 100,000 samples from the entire dataset can also be seen here.

![](/img/finalweek/boxplot-1day.png "1 Day Boxplot")
![](/img/finalweek/boxplot-1week.png "1 Week Boxplot")

### Improvements

Because of the size and complexity of the MIMIC database, there are many problems that can tackled. Here are some challenging areas that were beyond the scope of this data project, but that would have been interesting to include.

* Patient similarity

* Survival analysis (time-to-event prediction)

* Disease prediction